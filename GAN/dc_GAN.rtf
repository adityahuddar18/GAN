{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier-Bold;}
{\colortbl;\red255\green255\blue255;\red89\green156\blue62;\red23\green23\blue23;\red202\green202\blue202;
\red183\green111\blue179;\red212\green212\blue212;\red70\green137\blue204;\red67\green192\blue160;\red212\green214\blue154;
\red140\green211\blue254;\red167\green197\blue152;\red194\green126\blue101;\red113\green184\blue255;}
{\*\expandedcolortbl;;\cssrgb\c41569\c66275\c30980;\cssrgb\c11765\c11765\c11765;\cssrgb\c83137\c83137\c83137;
\cssrgb\c77255\c52549\c75294;\cssrgb\c86275\c86275\c86275;\cssrgb\c33725\c61176\c83922;\cssrgb\c30588\c78824\c69020;\cssrgb\c86275\c86275\c66667;
\cssrgb\c61176\c86275\c99608;\cssrgb\c70980\c80784\c65882;\cssrgb\c80784\c56863\c47059;\cssrgb\c50980\c77647\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\qj\partightenfactor0

\f0\b\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 # prompt: I need to build a machine learning model for recognition for either fake or original images.these are not deep fake image. this can be converted to deep convolutional gan?\cf4 \cb1 \strokec4 \
\
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.nn \cf5 \strokec5 as\cf4 \strokec4  nn\cb1 \
\cf5 \cb3 \strokec5 import\cf4 \strokec4  torch.optim \cf5 \strokec5 as\cf4 \strokec4  optim\cb1 \
\cf5 \cb3 \strokec5 from\cf4 \strokec4  torch.utils.data \cf5 \strokec5 import\cf4 \strokec4  DataLoader\cb1 \
\cf5 \cb3 \strokec5 from\cf4 \strokec4  torchvision \cf5 \strokec5 import\cf4 \strokec4  datasets\cf6 \strokec6 ,\cf4 \strokec4  transforms\cb1 \
\cf5 \cb3 \strokec5 from\cf4 \strokec4  torch.utils.tensorboard \cf5 \strokec5 import\cf4 \strokec4  SummaryWriter\cb1 \
\
\cf2 \cb3 \strokec2 # Define the Discriminator\cf4 \cb1 \strokec4 \
\cf7 \cb3 \strokec7 class\cf4 \strokec4  \cf8 \strokec8 Discriminator\cf4 \strokec4 (\cf8 \strokec8 nn\cf4 \strokec4 .\cf8 \strokec8 Module\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 __init__\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 , \cf10 \strokec10 in_features\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         super\cf6 \strokec6 ()\cf4 \strokec4 .\cf9 \strokec9 __init__\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .disc = nn.Sequential\cf6 \strokec6 (\cf4 \cb1 \strokec4 \
\cb3             nn.Linear\cf6 \strokec6 (\cf4 \strokec4 in_features\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 128\cf6 \strokec6 ),\cf4 \cb1 \strokec4 \
\cb3             nn.LeakyReLU\cf6 \strokec6 (\cf11 \strokec11 0.01\cf6 \strokec6 ),\cf4 \cb1 \strokec4 \
\cb3             nn.Linear\cf6 \strokec6 (\cf11 \strokec11 128\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 1\cf6 \strokec6 ),\cf4 \cb1 \strokec4 \
\cb3             nn.Sigmoid\cf6 \strokec6 (),\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 forward\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 , \cf10 \strokec10 x\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         \cf5 \strokec5 return\cf4 \strokec4  \cf10 \strokec10 self\cf4 \strokec4 .disc\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 # Define the Generator\cf4 \cb1 \strokec4 \
\cf7 \cb3 \strokec7 class\cf4 \strokec4  \cf8 \strokec8 Generator\cf4 \strokec4 (\cf8 \strokec8 nn\cf4 \strokec4 .\cf8 \strokec8 Module\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 __init__\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 , \cf10 \strokec10 z_dim\cf4 \strokec4 , \cf10 \strokec10 img_dim\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         super\cf6 \strokec6 ()\cf4 \strokec4 .\cf9 \strokec9 __init__\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .gen = nn.Sequential\cf6 \strokec6 (\cf4 \cb1 \strokec4 \
\cb3             nn.Linear\cf6 \strokec6 (\cf4 \strokec4 z_dim\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 256\cf6 \strokec6 ),\cf4 \cb1 \strokec4 \
\cb3             nn.LeakyReLU\cf6 \strokec6 (\cf11 \strokec11 0.01\cf6 \strokec6 ),\cf4 \cb1 \strokec4 \
\cb3             nn.Linear\cf6 \strokec6 (\cf11 \strokec11 256\cf6 \strokec6 ,\cf4 \strokec4  img_dim\cf6 \strokec6 ),\cf4 \cb1 \strokec4 \
\cb3             nn.Tanh\cf6 \strokec6 (),\cf4 \cb1 \strokec4 \
\cb3         \cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 forward\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 , \cf10 \strokec10 x\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         \cf5 \strokec5 return\cf4 \strokec4  \cf10 \strokec10 self\cf4 \strokec4 .gen\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 # Hyperparameters etc.\cf4 \cb1 \strokec4 \
\cb3 device = \cf12 \strokec12 "cuda"\cf4 \strokec4  \cf5 \strokec5 if\cf4 \strokec4  torch.cuda.is_available\cf6 \strokec6 ()\cf4 \strokec4  \cf5 \strokec5 else\cf4 \strokec4  \cf12 \strokec12 "cpu"\cf4 \cb1 \strokec4 \
\cb3 lr = \cf11 \strokec11 3e-4\cf4 \cb1 \strokec4 \
\cb3 z_dim = \cf11 \strokec11 64\cf4 \cb1 \strokec4 \
\cb3 batch_size = \cf11 \strokec11 32\cf4 \cb1 \strokec4 \
\cb3 num_epochs = \cf11 \strokec11 50\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 # Load the dataset\cf4 \cb1 \strokec4 \
\cb3 transform = transforms.Compose\cf6 \strokec6 ([\cf4 \cb1 \strokec4 \
\cb3     transforms.ToTensor\cf6 \strokec6 (),\cf4 \cb1 \strokec4 \
\cb3     transforms.Normalize\cf6 \strokec6 ((\cf11 \strokec11 0.5\cf6 \strokec6 ,),\cf4 \strokec4  \cf6 \strokec6 (\cf11 \strokec11 0.5\cf6 \strokec6 ,)),\cf4 \cb1 \strokec4 \
\cf6 \cb3 \strokec6 ])\cf4 \cb1 \strokec4 \
\cb3 dataset = datasets.MNIST\cf6 \strokec6 (\cf4 \strokec4 root=\cf12 \strokec12 "dataset/"\cf6 \strokec6 ,\cf4 \strokec4  transform=transform\cf6 \strokec6 ,\cf4 \strokec4  download=\cf7 \strokec7 True\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 loader = DataLoader\cf6 \strokec6 (\cf4 \strokec4 dataset\cf6 \strokec6 ,\cf4 \strokec4  batch_size=batch_size\cf6 \strokec6 ,\cf4 \strokec4  shuffle=\cf7 \strokec7 True\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 # Initialize the discriminator and generator\cf4 \cb1 \strokec4 \
\cb3 disc = Discriminator\cf6 \strokec6 (\cf11 \strokec11 784\cf6 \strokec6 )\cf4 \strokec4 .to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 gen = Generator\cf6 \strokec6 (\cf4 \strokec4 z_dim\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 784\cf6 \strokec6 )\cf4 \strokec4 .to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 # Define the loss function and optimizers\cf4 \cb1 \strokec4 \
\cb3 criterion = nn.BCELoss\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3 opt_disc = optim.Adam\cf6 \strokec6 (\cf4 \strokec4 disc.parameters\cf6 \strokec6 (),\cf4 \strokec4  lr=lr\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 opt_gen = optim.Adam\cf6 \strokec6 (\cf4 \strokec4 gen.parameters\cf6 \strokec6 (),\cf4 \strokec4  lr=lr\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 # Train the model\cf4 \cb1 \strokec4 \
\cb3 writer_fake = SummaryWriter\cf6 \strokec6 (\cf7 \strokec7 f\cf12 \strokec12 "logs/fake"\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 writer_real = SummaryWriter\cf6 \strokec6 (\cf7 \strokec7 f\cf12 \strokec12 "logs/real"\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 step = \cf11 \strokec11 0\cf4 \cb1 \strokec4 \
\cf5 \cb3 \strokec5 for\cf4 \strokec4  epoch \cf13 \strokec13 in\cf4 \strokec4  \cf9 \strokec9 range\cf6 \strokec6 (\cf4 \strokec4 num_epochs\cf6 \strokec6 ):\cf4 \cb1 \strokec4 \
\cb3     \cf5 \strokec5 for\cf4 \strokec4  batch_idx\cf6 \strokec6 ,\cf4 \strokec4  \cf6 \strokec6 (\cf4 \strokec4 real\cf6 \strokec6 ,\cf4 \strokec4  _\cf6 \strokec6 )\cf4 \strokec4  \cf13 \strokec13 in\cf4 \strokec4  \cf9 \strokec9 enumerate\cf6 \strokec6 (\cf4 \strokec4 loader\cf6 \strokec6 ):\cf4 \cb1 \strokec4 \
\cb3         real = real.view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 784\cf6 \strokec6 )\cf4 \strokec4 .to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         batch_size = real.shape\cf6 \strokec6 [\cf11 \strokec11 0\cf6 \strokec6 ]\cf4 \cb1 \strokec4 \
\
\cb3         \cf2 \strokec2 ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\cf4 \cb1 \strokec4 \
\cb3         noise = torch.randn\cf6 \strokec6 (\cf4 \strokec4 batch_size\cf6 \strokec6 ,\cf4 \strokec4  z_dim\cf6 \strokec6 )\cf4 \strokec4 .to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         fake = gen\cf6 \strokec6 (\cf4 \strokec4 noise\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         disc_real = disc\cf6 \strokec6 (\cf4 \strokec4 real\cf6 \strokec6 )\cf4 \strokec4 .view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         lossD_real = criterion\cf6 \strokec6 (\cf4 \strokec4 disc_real\cf6 \strokec6 ,\cf4 \strokec4  torch.ones_like\cf6 \strokec6 (\cf4 \strokec4 disc_real\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         disc_fake = disc\cf6 \strokec6 (\cf4 \strokec4 fake\cf6 \strokec6 )\cf4 \strokec4 .view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         lossD_fake = criterion\cf6 \strokec6 (\cf4 \strokec4 disc_fake\cf6 \strokec6 ,\cf4 \strokec4  torch.zeros_like\cf6 \strokec6 (\cf4 \strokec4 disc_fake\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         lossD = \cf6 \strokec6 (\cf4 \strokec4 lossD_real + lossD_fake\cf6 \strokec6 )\cf4 \strokec4  / \cf11 \strokec11 2\cf4 \cb1 \strokec4 \
\cb3         disc.zero_grad\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         lossD.backward\cf6 \strokec6 (\cf4 \strokec4 retain_graph=\cf7 \strokec7 True\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         opt_disc.step\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\
\cb3         \cf2 \strokec2 ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z)))\cf4 \cb1 \strokec4 \
\cb3         output = disc\cf6 \strokec6 (\cf4 \strokec4 fake\cf6 \strokec6 )\cf4 \strokec4 .view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         lossG = criterion\cf6 \strokec6 (\cf4 \strokec4 output\cf6 \strokec6 ,\cf4 \strokec4  torch.ones_like\cf6 \strokec6 (\cf4 \strokec4 output\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         gen.zero_grad\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         lossG.backward\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         opt_gen.step\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\
\cb3         \cf5 \strokec5 if\cf4 \strokec4  batch_idx == \cf11 \strokec11 0\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3             \cf9 \strokec9 print\cf6 \strokec6 (\cf4 \cb1 \strokec4 \
\cb3                 \cf7 \strokec7 f\cf12 \strokec12 "Epoch [\cf6 \strokec6 \{\cf4 \strokec4 epoch\cf6 \strokec6 \}\cf12 \strokec12 /\cf6 \strokec6 \{\cf4 \strokec4 num_epochs\cf6 \strokec6 \}\cf12 \strokec12 ] Batch \cf6 \strokec6 \{\cf4 \strokec4 batch_idx\cf6 \strokec6 \}\cf12 \strokec12 /\cf6 \strokec6 \{\cf9 \strokec9 len\cf6 \strokec6 (\cf4 \strokec4 loader\cf6 \strokec6 )\}\cf12 \strokec12  \\\cf4 \cb1 \strokec4 \
\cf12 \cb3 \strokec12                       Loss D: \cf6 \strokec6 \{\cf4 \strokec4 lossD\cf11 \strokec11 :.4f\cf6 \strokec6 \}\cf12 \strokec12 , loss G: \cf6 \strokec6 \{\cf4 \strokec4 lossG\cf11 \strokec11 :.4f\cf6 \strokec6 \}\cf12 \strokec12 "\cf4 \cb1 \strokec4 \
\cb3             \cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cb3             \cf5 \strokec5 with\cf4 \strokec4  torch.no_grad\cf6 \strokec6 ():\cf4 \cb1 \strokec4 \
\cb3                 fake = gen\cf6 \strokec6 (\cf4 \strokec4 fixed_noise\cf6 \strokec6 )\cf4 \strokec4 .reshape\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 28\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 28\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3                 data = real.reshape\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 28\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 28\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3                 img_grid_fake = torchvision.utils.make_grid\cf6 \strokec6 (\cf4 \strokec4 fake\cf6 \strokec6 ,\cf4 \strokec4  normalize=\cf7 \strokec7 True\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3                 img_grid_real = torchvision.utils.make_grid\cf6 \strokec6 (\cf4 \strokec4 data\cf6 \strokec6 ,\cf4 \strokec4  normalize=\cf7 \strokec7 True\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cb3                 writer_fake.add_image\cf6 \strokec6 (\cf4 \cb1 \strokec4 \
\cb3                     \cf12 \strokec12 "Fake Images"\cf6 \strokec6 ,\cf4 \strokec4  img_grid_fake\cf6 \strokec6 ,\cf4 \strokec4  global_step=step\cb1 \
\cb3                 \cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3                 writer_real.add_image\cf6 \strokec6 (\cf4 \cb1 \strokec4 \
\cb3                     \cf12 \strokec12 "Real Images"\cf6 \strokec6 ,\cf4 \strokec4  img_grid_real\cf6 \strokec6 ,\cf4 \strokec4  global_step=step\cb1 \
\cb3                 \cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3                 step += \cf11 \strokec11 1\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 # Convert the model to a Deep Convolutional GAN\cf4 \cb1 \strokec4 \
\cf7 \cb3 \strokec7 class\cf4 \strokec4  \cf8 \strokec8 DCGAN_Discriminator\cf4 \strokec4 (\cf8 \strokec8 nn\cf4 \strokec4 .\cf8 \strokec8 Module\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 __init__\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         super\cf6 \strokec6 ()\cf4 \strokec4 .\cf9 \strokec9 __init__\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .conv1 = nn.Conv2d\cf6 \strokec6 (\cf11 \strokec11 1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 32\cf6 \strokec6 ,\cf4 \strokec4  kernel_size=\cf11 \strokec11 4\cf6 \strokec6 ,\cf4 \strokec4  stride=\cf11 \strokec11 2\cf6 \strokec6 ,\cf4 \strokec4  padding=\cf11 \strokec11 1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .conv2 = nn.Conv2d\cf6 \strokec6 (\cf11 \strokec11 32\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 64\cf6 \strokec6 ,\cf4 \strokec4  kernel_size=\cf11 \strokec11 4\cf6 \strokec6 ,\cf4 \strokec4  stride=\cf11 \strokec11 2\cf6 \strokec6 ,\cf4 \strokec4  padding=\cf11 \strokec11 1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .conv3 = nn.Conv2d\cf6 \strokec6 (\cf11 \strokec11 64\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 128\cf6 \strokec6 ,\cf4 \strokec4  kernel_size=\cf11 \strokec11 4\cf6 \strokec6 ,\cf4 \strokec4  stride=\cf11 \strokec11 2\cf6 \strokec6 ,\cf4 \strokec4  padding=\cf11 \strokec11 1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .fc1 = nn.Linear\cf6 \strokec6 (\cf11 \strokec11 128\cf4 \strokec4  * \cf11 \strokec11 7\cf4 \strokec4  * \cf11 \strokec11 7\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 forward\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 , \cf10 \strokec10 x\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         x = F.leaky_relu\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .conv1\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ),\cf4 \strokec4  \cf11 \strokec11 0.2\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         x = F.leaky_relu\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .conv2\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ),\cf4 \strokec4  \cf11 \strokec11 0.2\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         x = F.leaky_relu\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .conv3\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ),\cf4 \strokec4  \cf11 \strokec11 0.2\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         x = x.view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 128\cf4 \strokec4  * \cf11 \strokec11 7\cf4 \strokec4  * \cf11 \strokec11 7\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         x = F.sigmoid\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .fc1\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         \cf5 \strokec5 return\cf4 \strokec4  x\cb1 \
\
\cf7 \cb3 \strokec7 class\cf4 \strokec4  \cf8 \strokec8 DCGAN_Generator\cf4 \strokec4 (\cf8 \strokec8 nn\cf4 \strokec4 .\cf8 \strokec8 Module\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 __init__\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         super\cf6 \strokec6 ()\cf4 \strokec4 .\cf9 \strokec9 __init__\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .fc1 = nn.Linear\cf6 \strokec6 (\cf11 \strokec11 100\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 128\cf4 \strokec4  * \cf11 \strokec11 7\cf4 \strokec4  * \cf11 \strokec11 7\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .conv1 = nn.ConvTranspose2d\cf6 \strokec6 (\cf11 \strokec11 128\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 64\cf6 \strokec6 ,\cf4 \strokec4  kernel_size=\cf11 \strokec11 4\cf6 \strokec6 ,\cf4 \strokec4  stride=\cf11 \strokec11 2\cf6 \strokec6 ,\cf4 \strokec4  padding=\cf11 \strokec11 1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .conv2 = nn.ConvTranspose2d\cf6 \strokec6 (\cf11 \strokec11 64\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 32\cf6 \strokec6 ,\cf4 \strokec4  kernel_size=\cf11 \strokec11 4\cf6 \strokec6 ,\cf4 \strokec4  stride=\cf11 \strokec11 2\cf6 \strokec6 ,\cf4 \strokec4  padding=\cf11 \strokec11 1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         \cf10 \strokec10 self\cf4 \strokec4 .conv3 = nn.ConvTranspose2d\cf6 \strokec6 (\cf11 \strokec11 32\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 1\cf6 \strokec6 ,\cf4 \strokec4  kernel_size=\cf11 \strokec11 4\cf6 \strokec6 ,\cf4 \strokec4  stride=\cf11 \strokec11 2\cf6 \strokec6 ,\cf4 \strokec4  padding=\cf11 \strokec11 1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cb3     \cf7 \strokec7 def\cf4 \strokec4  \cf9 \strokec9 forward\cf4 \strokec4 (\cf10 \strokec10 self\cf4 \strokec4 , \cf10 \strokec10 x\cf4 \strokec4 )\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3         x = F.relu\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .fc1\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         x = x.view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 128\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 7\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 7\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         x = F.relu\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .conv1\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         x = F.relu\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .conv2\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         x = F.tanh\cf6 \strokec6 (\cf10 \strokec10 self\cf4 \strokec4 .conv3\cf6 \strokec6 (\cf4 \strokec4 x\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         \cf5 \strokec5 return\cf4 \strokec4  x\cb1 \
\
\cf2 \cb3 \strokec2 # Train the DCGAN model\cf4 \cb1 \strokec4 \
\cb3 disc = DCGAN_Discriminator\cf6 \strokec6 ()\cf4 \strokec4 .to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 gen = DCGAN_Generator\cf6 \strokec6 ()\cf4 \strokec4 .to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 criterion = nn.BCELoss\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3 opt_disc = optim.Adam\cf6 \strokec6 (\cf4 \strokec4 disc.parameters\cf6 \strokec6 (),\cf4 \strokec4  lr=lr\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3 opt_gen = optim.Adam\cf6 \strokec6 (\cf4 \strokec4 gen.parameters\cf6 \strokec6 (),\cf4 \strokec4  lr=lr\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cf5 \cb3 \strokec5 for\cf4 \strokec4  epoch \cf13 \strokec13 in\cf4 \strokec4  \cf9 \strokec9 range\cf6 \strokec6 (\cf4 \strokec4 num_epochs\cf6 \strokec6 ):\cf4 \cb1 \strokec4 \
\cb3     \cf5 \strokec5 for\cf4 \strokec4  batch_idx\cf6 \strokec6 ,\cf4 \strokec4  \cf6 \strokec6 (\cf4 \strokec4 real\cf6 \strokec6 ,\cf4 \strokec4  _\cf6 \strokec6 )\cf4 \strokec4  \cf13 \strokec13 in\cf4 \strokec4  \cf9 \strokec9 enumerate\cf6 \strokec6 (\cf4 \strokec4 loader\cf6 \strokec6 ):\cf4 \cb1 \strokec4 \
\cb3         real = real.to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         batch_size = real.shape\cf6 \strokec6 [\cf11 \strokec11 0\cf6 \strokec6 ]\cf4 \cb1 \strokec4 \
\
\cb3         \cf2 \strokec2 ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\cf4 \cb1 \strokec4 \
\cb3         noise = torch.randn\cf6 \strokec6 (\cf4 \strokec4 batch_size\cf6 \strokec6 ,\cf4 \strokec4  \cf11 \strokec11 100\cf6 \strokec6 )\cf4 \strokec4 .to\cf6 \strokec6 (\cf4 \strokec4 device\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         fake = gen\cf6 \strokec6 (\cf4 \strokec4 noise\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         disc_real = disc\cf6 \strokec6 (\cf4 \strokec4 real\cf6 \strokec6 )\cf4 \strokec4 .view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         lossD_real = criterion\cf6 \strokec6 (\cf4 \strokec4 disc_real\cf6 \strokec6 ,\cf4 \strokec4  torch.ones_like\cf6 \strokec6 (\cf4 \strokec4 disc_real\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         disc_fake = disc\cf6 \strokec6 (\cf4 \strokec4 fake\cf6 \strokec6 )\cf4 \strokec4 .view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         lossD_fake = criterion\cf6 \strokec6 (\cf4 \strokec4 disc_fake\cf6 \strokec6 ,\cf4 \strokec4  torch.zeros_like\cf6 \strokec6 (\cf4 \strokec4 disc_fake\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         lossD = \cf6 \strokec6 (\cf4 \strokec4 lossD_real + lossD_fake\cf6 \strokec6 )\cf4 \strokec4  / \cf11 \strokec11 2\cf4 \cb1 \strokec4 \
\cb3         disc.zero_grad\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         lossD.backward\cf6 \strokec6 (\cf4 \strokec4 retain_graph=\cf7 \strokec7 True\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         opt_disc.step\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\
\cb3         \cf2 \strokec2 ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z)))\cf4 \cb1 \strokec4 \
\cb3         output = disc\cf6 \strokec6 (\cf4 \strokec4 fake\cf6 \strokec6 )\cf4 \strokec4 .view\cf6 \strokec6 (\cf11 \strokec11 -1\cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\cb3         lossG = criterion\cf6 \strokec6 (\cf4 \strokec4 output\cf6 \strokec6 ,\cf4 \strokec4  torch.ones_like\cf6 \strokec6 (\cf4 \strokec4 output\cf6 \strokec6 ))\cf4 \cb1 \strokec4 \
\cb3         gen.zero_grad\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         lossG.backward\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\cb3         opt_gen.step\cf6 \strokec6 ()\cf4 \cb1 \strokec4 \
\
\cb3         \cf5 \strokec5 if\cf4 \strokec4  batch_idx == \cf11 \strokec11 0\cf6 \strokec6 :\cf4 \cb1 \strokec4 \
\cb3             \cf9 \strokec9 print\cf6 \strokec6 (\cf4 \cb1 \strokec4 \
\cb3                 \cf7 \strokec7 f\cf12 \strokec12 "Epoch [\cf6 \strokec6 \{\cf4 \strokec4 epoch\cf6 \strokec6 \}\cf12 \strokec12 /\cf6 \strokec6 \{\cf4 \strokec4 num_epochs\cf6 \strokec6 \}\cf12 \strokec12 ] Batch \cf6 \strokec6 \{\cf4 \strokec4 batch_idx\cf6 \strokec6 \}\cf12 \strokec12 /\cf6 \strokec6 \{\cf9 \strokec9 len\cf6 \strokec6 (\cf4 \strokec4 loader\cf6 \strokec6 )\}\cf12 \strokec12  \\\cf4 \cb1 \strokec4 \
\cf12 \cb3 \strokec12                       Loss D: \cf6 \strokec6 \{\cf4 \strokec4 lossD\cf11 \strokec11 :.4f\cf6 \strokec6 \}\cf12 \strokec12 , loss G: \cf6 \strokec6 \{\cf4 \strokec4 lossG\cf11 \strokec11 :.4f\cf6 \strokec6 \}\cf12 \strokec12 "\cf4 \cb1 \strokec4 \
\cb3             \cf6 \strokec6 )\cf4 \cb1 \strokec4 \
\
\cb3             \cf5 \strokec5 with\cf4 \strokec4  torch.no_grad\cf6 \strokec6 ():\cf4 \cb1 \strokec4 \
\
}